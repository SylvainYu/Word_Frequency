n-gramRecords-Prediction.ipnb中读取数据以后，在Records_data.txt中写入经过处理的每个句子（一共5911个句子）。所谓“处理”，指的是去除非中文字符意外的元素，将无效字符都用空格替代；然后将句子jieba分词成为词语以后写入Records_data.txt中，仍旧按照每个句子的排列顺序，将单个句子涉及的词语在一行中罗列；这样也就有5911行。通过这样的处理，每个句子中有那些词语，它们的顺序也就保存下来。

=================
questions.txt内容：
施工单位现场漏做[MASK]。
资料检查未能发现[MASK]。
=================

2020-9-21-14:45时候测试失败。预测结果都显示“记录”。但基础数据来源是宝山监督站。

2020-9-21-14:48将questions.txt首句中“未见”变更成“漏做”，基础数据变更成邬嘉荪，再行测试。邬嘉荪监督记录供3753行。测试仍旧失败，因结果仍旧是两个“记录”。

2020-9-21-14:54questions.txt变更词语顺序，由“...漏做[MASK]。”变更成“...[MASK]漏做。”尝试。仍然失败，结果仍旧是两个“记录”。打算指定词语后，显示它附近那些文字出现概率最大。
其实，就是逐句琢磨predict()函数。---->看不大懂。

（1）打算尝试将整个监督记录内容都作为基础数据纳入，然后测试。（2）或者将测试数据扩大，在原版新闻数据测试中，它采用的questions.txt内容就比较多。（3）还得重新阅读博主原文，进一步加深理解。



=================
=================
=================
ngram-Records.ipnb模块中，
cell[37]“遍历所有预处理过的文件”注释下，
range()和zip()用法需要明确。后续还有collection模块的Counter()函数。
*****************************
Python3 range() 函数返回的是一个可迭代对象（类型是对象），而不是列表类型， 所以打印的时候不会打印列表。
通常与range()配套使用的Python3 list() 函数是对象迭代器，可以把range()返回的可迭代对象转为一个列表，返回的变量类型为列表。

zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的对象，这样做的好处是节约了不少的内存。
通常我们可以使用 list() 转换来输出列表。如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用*号操作符，可以将元组解压为列表。

collection模块的Counter()函数用于支持便捷和快速地计数。另，collection模块中也有Counter类，是dict子类，用于计数可哈希的对象。是一个无序的容器，元素被作为字典的key存储，其技术作为地点的value存储。
*****************************



2020-9对原始代码的Note
******************************
-
get_news_text模块
=============
一个函数一个单元(cell)，整洁的格式，方便查看方便修改。

cell[3]: getOneArtical(url)
开头的函数说明提及返回的类型是“二元组”，是tuple么？soup = BeautifulSoup(re.text)之后，soup.find().text.strip()返回的是tuple？

cell[4]: getPageLinks()
该函数中有一个global browser，这样browser变量声明为全局，整个模块都能使用browser了？
**********************************
后面还有browser.find_elements_by_xpath()，这是一个（全局）类？
google没有查到browser类，在Selenium-Python文档中搜索到.find_elements_by_xpath()是selenium模块webdriver.common.by下的，一次查找多个元素（返回一个list列表）。
**********************************
cell[5]中看到了browser引用，是全局。而且引用全是和浏览器设置、信息获取等相关。


preprocessing模块
=================

cell[2]中wordtable没有生成，代码中直接读取wordtable文件。cell[5]中可以看出，当初cell[2]读取的仅仅是空文件。

cell[3]和cell[4]中分别取出停止词，加载用户词典。cell[4]中word_table = {}生成待用。
cell[3]中去停止词使用stopwords = set(map(lamba x:x.strip(), stopwords)) # 去除末尾换行符。这样一个我没有用过的方法？？？后来在ngram模块中也这样操作，不晓得有啥优缺。

每读取一个文件才进行一次处理，去除特殊字符全角空格啥的，然后计算句子数量。后续代码中还有辨识有效中文字符，无效的全部用空格代替！
cell[5]中使用了enumerate(word_table)函数，将整理的来的词汇列表写入wordtable.txt文件。
**********************************
enumerate()是python内置函数，对于一个可迭代的(iterable)/可遍历的对象（例如列表、字符串），enumerate将其组成一个索引苏烈，利用它可同时获得索引和值；enumerate多用在for循环中得到计数；enumerate()返回的是一个enumerate对象。
**********************************
在监督记录中有些文字没有标点符号，只用空格代替；估计是为了输入方便偷懒。其实可以用Excel中的数字序号来断句，再加上空格。计算句子数量有所偏差，但断句以后将来主题辨识能大致区分安全安装土建属性。有这样一个思考就行。


ngram模块
===========
cell[2]中，n = 3。

cell[4]，all_word = []，随后all_word是通过读取前面preprocessing模块生成woadtable.txt文件而生成的。

cell[9]中准确率计算也不晓得是啥原理。