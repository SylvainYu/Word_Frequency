{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 21:42:15,321:INFO:collecting all words and their counts\n",
      "2020-07-07 21:42:15,322:INFO:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-07-07 21:42:15,323:INFO:collected 15 word types from a corpus of 16 raw words and 2 sentences\n",
      "2020-07-07 21:42:15,323:INFO:Loading a fresh vocabulary\n",
      "2020-07-07 21:42:15,324:INFO:effective_min_count=1 retains 15 unique words (100% of original 15, drops 0)\n",
      "2020-07-07 21:42:15,324:INFO:effective_min_count=1 leaves 16 word corpus (100% of original 16, drops 0)\n",
      "2020-07-07 21:42:15,325:INFO:deleting the raw counts dictionary of 15 items\n",
      "2020-07-07 21:42:15,325:INFO:sample=0.001 downsamples 15 most-common words\n",
      "2020-07-07 21:42:15,325:INFO:downsampling leaves estimated 2 word corpus (13.7% of prior 16)\n",
      "2020-07-07 21:42:15,326:INFO:estimated required memory for 15 words and 100 dimensions: 19500 bytes\n",
      "2020-07-07 21:42:15,326:INFO:resetting layer weights\n",
      "2020-07-07 21:42:15,330:INFO:training model with 3 workers on 15 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-07-07 21:42:15,333:INFO:worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-07 21:42:15,334:INFO:worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-07 21:42:15,335:INFO:worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-07 21:42:15,336:INFO:EPOCH - 1 : training on 16 raw words (2 effective words) took 0.0s, 874 effective words/s\n",
      "2020-07-07 21:42:15,339:INFO:worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-07 21:42:15,339:INFO:worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-07 21:42:15,340:INFO:worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-07 21:42:15,340:INFO:EPOCH - 2 : training on 16 raw words (2 effective words) took 0.0s, 1177 effective words/s\n",
      "2020-07-07 21:42:15,344:INFO:worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-07 21:42:15,344:INFO:worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-07 21:42:15,345:INFO:worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-07 21:42:15,345:INFO:EPOCH - 3 : training on 16 raw words (2 effective words) took 0.0s, 1095 effective words/s\n",
      "2020-07-07 21:42:15,348:INFO:worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-07 21:42:15,349:INFO:worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-07 21:42:15,349:INFO:worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-07 21:42:15,350:INFO:EPOCH - 4 : training on 16 raw words (1 effective words) took 0.0s, 404 effective words/s\n",
      "2020-07-07 21:42:15,353:INFO:worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-07 21:42:15,354:INFO:worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-07 21:42:15,354:INFO:worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-07 21:42:15,355:INFO:EPOCH - 5 : training on 16 raw words (2 effective words) took 0.0s, 911 effective words/s\n",
      "2020-07-07 21:42:15,355:INFO:training on a 80 raw words (9 effective words) took 0.0s, 372 effective words/s\n",
      "2020-07-07 21:42:15,356:WARNING:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['但', '由于', '中文', '没有', '像', '英文', '那样', '自带', '天然', '的', '分词'], ['所以', '我们', '第一步', '采用', '分词']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.5583848e-03,  2.6970399e-03, -1.2172501e-03,  3.2078002e-03,\n",
       "        9.6469920e-04, -3.2607077e-05, -3.1335966e-03, -3.5397687e-03,\n",
       "       -5.6101830e-04, -9.1895583e-04, -3.4888643e-03,  4.6463269e-03,\n",
       "        9.5358153e-04, -2.4702288e-03, -3.9558271e-03,  1.6674225e-03,\n",
       "       -3.1730600e-03,  1.9183324e-03,  2.9911469e-03,  5.6848908e-04,\n",
       "        3.3112320e-03, -1.2258741e-03, -2.7341368e-03,  7.0156489e-04,\n",
       "        1.7494481e-03,  2.9777982e-03,  5.6252896e-04,  1.5835658e-03,\n",
       "        1.6652673e-03, -2.7954884e-04, -4.6176314e-03,  4.4563566e-03,\n",
       "        3.5713415e-03,  3.2752291e-03, -4.7316537e-03,  9.5640971e-06,\n",
       "       -2.0155136e-03,  2.1367250e-03,  3.4871281e-03, -3.2997059e-04,\n",
       "        4.0590819e-03, -4.9957335e-03, -2.3859406e-03,  9.3087461e-04,\n",
       "       -3.3690680e-03,  3.9017252e-03,  3.0573404e-03,  1.1532312e-03,\n",
       "       -1.7681661e-03, -2.6181939e-03,  2.2465521e-03,  1.0621066e-03,\n",
       "        2.8484552e-03,  3.6842572e-03, -8.4944291e-04, -3.2097539e-03,\n",
       "        2.8698624e-03,  1.1170732e-03, -5.1185006e-04, -3.7206613e-04,\n",
       "        4.1308071e-04, -3.6566299e-03,  1.8408025e-03, -4.1242656e-03,\n",
       "        3.8348043e-03, -3.0380876e-03,  2.7404223e-03,  8.1276265e-04,\n",
       "       -9.6027250e-04,  3.8109864e-03, -4.0008873e-03,  1.4119160e-03,\n",
       "        2.6601623e-03,  1.9482120e-03,  2.5053213e-03, -3.8886650e-05,\n",
       "       -3.5243586e-03,  3.5968176e-03, -8.1511789e-05,  2.1098909e-04,\n",
       "       -2.6926028e-03, -4.4013504e-03, -2.3995381e-05, -3.3620801e-03,\n",
       "       -1.0038771e-03, -8.6618541e-04, -8.6649251e-04,  3.8360688e-03,\n",
       "       -2.5485728e-03,  5.6854630e-04, -3.9097646e-04, -2.5569997e-03,\n",
       "        3.1540117e-03,  6.7453668e-04,  1.3760203e-03, -1.2004578e-03,\n",
       "       -6.0410053e-04,  3.5911032e-03,  2.3893227e-03,  2.8368114e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据CSDN博客CoderPai文章，gensim.word2vec函数使用练习\n",
    "\n",
    "# 引入word2vec\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 引入日志配置\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "# 引入分词工具\n",
    "import jieba\n",
    "\n",
    "# 引入数据集\n",
    "raw_sentences = [\"但由于中文没有像英文那样自带天然的分词\", \"所以我们第一步采用分词\"]\n",
    "\n",
    "# 切分词汇\n",
    "sentences = []\n",
    "for s in raw_sentences:\n",
    "    tmp = []\n",
    "    for item in jieba.cut(s):\n",
    "        tmp.append(item)\n",
    "    sentences.append(tmp)\n",
    "\n",
    "print(sentences)\n",
    "\n",
    "# 构建模型，未去停止词状态下\n",
    "model = word2vec.Word2Vec(sentences, min_count=1)\n",
    "\n",
    "# 进行词向量输出\n",
    "model['中文']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'但': <gensim.models.keyedvectors.Vocab object at 0x0000028933C3C0C8>, '由于': <gensim.models.keyedvectors.Vocab object at 0x0000028933F59F08>, '中文': <gensim.models.keyedvectors.Vocab object at 0x0000028933F59F88>, '没有': <gensim.models.keyedvectors.Vocab object at 0x0000028933F59FC8>, '像': <gensim.models.keyedvectors.Vocab object at 0x0000028933C367C8>, '英文': <gensim.models.keyedvectors.Vocab object at 0x0000028933C36948>, '那样': <gensim.models.keyedvectors.Vocab object at 0x0000028933218D48>, '自带': <gensim.models.keyedvectors.Vocab object at 0x0000028930515908>, '天然': <gensim.models.keyedvectors.Vocab object at 0x0000028933F59E48>, '的': <gensim.models.keyedvectors.Vocab object at 0x0000028933C36A08>, '分词': <gensim.models.keyedvectors.Vocab object at 0x0000028930515DC8>, '所以': <gensim.models.keyedvectors.Vocab object at 0x0000028930515A88>, '我们': <gensim.models.keyedvectors.Vocab object at 0x0000028930515788>, '第一步': <gensim.models.keyedvectors.Vocab object at 0x0000028930515D88>, '采用': <gensim.models.keyedvectors.Vocab object at 0x0000028930515C88>}\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.vocab)\n",
    "#print(len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
